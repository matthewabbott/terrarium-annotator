  Yo! I could use your help creating an @SPEC.md file and planned architecture documentation for this project!

  You might be able to get a sense of what it's about from the existing stuff, but this is all from a previous attempt and I'd be okay with discarding basically all of it. It's still worth looking at some of the intended roadmap and stuff. But what I'd really appreciate is if you'd interview me in great detail using the AskUserQuestionTool about whatsoever you need or desire to know more about -- anything: technical implementation, UI & UX, concerns, tradeoffs, aspirations, desired end result. Please try to make sure the questions are not obvious (though I'm still happy to answer questions that might be obvious too. Ask as many as you want).

  But okay, let me tell you about my goals. The project is called 'terrarium-annotator' because the idea is that it will use my local 'digital terrarium' AI agent on my local vLLM server to annotate a corpus. You can see the setup for the local agent in `~/Programming/terrarium-agent`.

  As for what I'll be annotating, my first goal is to annotate the `banished.db` corpus in the project root. banished.db is a database of all 'posts' made in a forum game known as 'banished quest'. The story features a 'quest master' (like a tabletop roleplaying game's dungeon master) who writes what happens, and then 'players' that vote on what the main character does next, as well as any forum posts by players in the meantime while things are going on.

  I have a few goals. First and foremost, I would like to create a glossary of all nonstandard terms in banished quest. For example, the quest uses the term 'vys' to describe what's more commonly known as 'mana' in fantasy in general, and the term 'vatis' for people that use vys to cast magic (essentially, vatis means wizard or sorcerer, but there are cultural specifics to the setting). There are also many characters and locations and other things that could use a glossary entry. (Eg, 'Rhynia' refers to the ruined fantasy roman-like empire in the setting). Zaahir is a brother of the main character Mikhael Abdul-Hakim, so he too should have a glossary or codex entry. I'd like to have an LLM iteratively read through the whole quest, and whenever it encounters a nonstandard term, it should either add that term to the glossary, or pull the existing glossary entry for that term into its context and then update its new understanding of the term from what it's been reading recently. When updating the glossary, I'd also like to include a reference: what post the new information came from. Posts have an ID and are also organized into 'threads' which are denoted by their 'opening post'. So to reference a specific post, you ideally want the reference in the form of <opening_post_id>#<post_id>. Eg, on a website that hosts an archive of this story, you can reference the post with ID 32266779 via the URL https://steelbea.me/voyage/32266754#32266779, where 32266754 is the ID of the opening post. I think, by default, these references probably should not all be dumped into the LLM chat context when it pulls a glossary entry, but perhaps there should be a tool that allows the LLM to read old posts if it deems that necessary?

 In any case, the glossary and references are the most important thing. I would like to use the glossary to:
  - construct wiki pages for Banished Quest, complete with backlinks to other wiki pages that mention that term
    - (which means maybe glossary entries should be able to reference other glossary entries)
  - augment a vocabulary of semant embeddings to include these jargon terms and thereby enable semantic-searching the corpus of banished quest (especially for fantasy terms and specific characters)

  We may need to have some sort of handling for jargon terms that come up constantly. Eg, as I previously mentioned, 'vys' is the term for mana, and it appears in essentially every thread (threads essentially being one 'chapter' of the story). The references to vys may balloon, so maybe we want to reference it only once per thread or something? Or take care to prompt our LLM to only update the glossary when it feels it has learned new information about a term. But on the other hand, for side-cahracter that rarely show up, it might be worthwhile to reference all or most posts they appear. We also want to be careful that character bios aren't a nitty-gritty recap of every action the character took, except perhaps for characters with a very small role. I'm not sure how to address these issues exactly. It's also possible that the best method is to leave qualitative decisions to the annotator agent (currently: Qwen3-Next-80B-A3B-Instruct-AWQ-4bit). Or perhaps to run through the story once to get an initial glossary, then run through it _again_ with that glossary available for reference but a slightly new prompt to decide how best to _revise_ the glossary, with the benefit of hindsight, in some sense.

  Speaking of hindsight, we will also need a method for automated compaction of context. I believe at present my local Qwen instance has a 262144 token KV cache size, which it can make full use of if this is the only program making requests against it. Nevertheless, Banished Quest is a long story, and we will need to compact the context many times. To that end, perhaps we want some sort of 'story so far' glossary entry? Or a separate tool for keeping such things in mind? And of course we need a schema for performing the context compaction. (Though if we have a second local agent performing compaction, we need to take care to not exceed the kv cache limits, so maybe we want our max context to be smaller than the full 262144. On the other hand, I expect this to run in the background for days, so some slowness is fine as long as it's not in the hot loop)

  Lastly, an aspirational feature I would like to include is 'agent context snapshots'. I would like for it to be possible for a future annotator agent to _rehydrate_ the context of a past annotator in order to ask it for further information about the edit it made. This is a complex feature, as it would require:
  - tracking blame in glossary modifications
  - saving all context histories and pegging them to the glossary revision blame
  - exposing the blame to the current annotator agent in a way that doesn't pollute the context (likely only upon request?)
  - loading the past annotator's context and spinning it up as well (perhaps I need to double my kv cache size, or half the allowed context length)
  - facilitating two-way communication between the old context agent and the current agent.
    - and handling edge cases like the old agent being dangerously near context compaction
  - spinning down the old agent upon the current agent's satisfaction, and then returning to the 'read story' agentic loop

 We also of course need to figure out how the agentic loop works to allow the agent to walk forward through the story. This is an aspirational feature, and probably something we would want to do after the core loop is working. However, I think this feature, when refined, has the potential to be incredibly powerful. It is, in some sense, the cleverest idea in this project, so I'm quite attached to it. The baseline project needs to exist first, however.

  To that end, I am not sure what the architecture should be. I do not know what components I should have, what their responsibilities should be, what their inputs will be, or what their outputs will be. The architecture is quite important, so I'd appreciate if you could put on your senior designer/engineer hat to help determine what would be best-practice for our grand aspirations.

  Finally, while the fantasy story corpus is the first corpus I would like to annotate in this manner, I would also like to later annotate other stories and other kinds of documents. For example, I would like to pore over building code documents and construct a similar glossary of their jargon terms (or terms used in a highly specific manner as compared to colloquial use, such as 'egress'). This too is an aspirational feature, but I hope our design can take into account the possibility of different datasets.

So okay, that was a lot! Hopefully now you understand my dreams to some extent, but I could really use your help turning them into an @SPEC.md and architecture documentation, plus any other docs you think we could use. We should make sure that future agents (eg, you after context compaction), can read those docs and understand our goals. And I'd really appreciate it if you could serve as my technical expert and use the AskUserQuestionTool to build out your own mental map of exactly what I am aiming for and what we will need, as mentioned above. I have a fair bit of low-resolution technical knowledge, so I should be able to answer anything, but if something is a within-component implementation detail, you can also use your best judgement (or most likely, we can figure out the specifics later as long as our architecture is solid). Ask any questions and many questions, since we are trying to create a bible from whence the whole sproject shall spring.

Thanks so much! 